
        <!DOCTYPE html>
        <html>
            <head>
                <meta http-equiv="Content-Type" content="text/html; charset=gb2312">
                <title>Word2vec with Pre-trained Weights - Jimmy Z. Hu's Blog</title>
                <style rel="stylesheet" type="text/css">
                    body {font-family: Georgia; font-size: 17px;}
h2 {margin-top: 40px; border-bottom: 1px solid #999; text-transform: uppercase;}
p {text-align: left; line-height: 1.4em;}
pre {
    background: #f4f4f4; border: 1px solid #ddd; border-left: 3px solid #9f9f9f; 
    color: #666; page-break-inside: avoid; font-family: monospace; font-size: 15px; 
    line-height: 1.1; max-width: 100%; overflow: auto; padding: 0.5em 0.5em; 
    display: block; word-wrap: break-word;
}
li {line-height: 1.25em;}
a:link {text-decoration: none; color: blue;}
a:visited {text-decoration: none; color: blue;}
.container {width: 750px; margin-left: auto; margin-right: auto; padding: 50px 0 50px 0;}
.title {text-align: left;}
.katex {font-size: 1em !important;} 
table {width: 100%%;}
table, th, td {border: 1px solid black;}

                </style>
                <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
                <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
                <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script>
                <script>
                    document.addEventListener("DOMContentLoaded", function() {
                        renderMathInElement(document.body, {
                            delimiters: [
                              {left: "$$", right: "$$", display: true},
                              {left: "$", right: "$", display: false}
                            ] 
                        });
                    });
                </script>
            </head>
            <body>
                <div class="container">
                    <h1 class="title">Word2vec with Pre-trained Weights</h1>
                    2020-07-26
                    <span style="float:right; _position:relative;">
                        <a href="/home">HOME</a>
                        &ensp;
                        <a href="/notes">NOTES</a> &ensp; <a href="../">RELATED</a>
                    </span><br/>
                    <h2>Introduction</h2>
<p>The corpus chosen to train word2vec should be similar to the task in which the word vector is to be used. Many researches show that corpus is more important than the model, so it is necessary to collect large and task-relevant corpus to train the word vector. However, training word2vec from scratch can be both time and space consuming. All efforts can be senseless if the corpus is not large enough or of a low quality. One solution to this is to initializing the model with relevant, pre-trained word2vec weights. <a href="https://radimrehurek.com/gensim/">Gensim</a> is a powerful NLP tool that supports incremental online algorithms, which perfectly fit the scenario we are facing.</p>
<h2>Data preparation and preprocessing</h2>
<h3>Corpus for training word2vec</h3>
<p><code>gensim.models.word2vec.LineSentence</code> streams corpus from file and thus prevents buffer overflow. Therefore, it would be efficient to store all cleaned and segmented text into a local file for later modeling.</p>
<h3>Pre-trained weights</h3>
<p>These can be downloaded from the internet. Researchers has developed tons of pre-trained weights based on different types of corpora. We just need to carefully pick the one that is most relative to our task.</p>
<ul>
<li><a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit">Google’s pre-trained model</a></li>
<li><a href="https://ai.tencent.com/ailab/nlp/en/index.html">Tencent Natural Language Processing (NLP) Research</a></li>
<li><a href="https://github.com/Embedding/Chinese-Word-Vectors">Chinese Word Vectors</a></li>
<li><a href="https://wikipedia2vec.github.io/wikipedia2vec/pretrained/">Wikipedia2vec</a></li>
</ul>
<h2>Incremental training with Gensim</h2>
<pre><code>from gensim.models import KeyedVectors<br>from gensim.models.word2vec import LineSentence, Word2Vec<br><br>sentences = LineSentence('corpus.txt')<br>model_2 = Word2Vec(size=200, window=5, min_count=5, workers=8)<br>model_2.build_vocab(sentences)<br>total_examples = model_2.corpus_count<br>model = KeyedVectors.load_word2vec_format('pre-trained.txt', binary=False)<br>model_2.build_vocab([list(model.vocab.keys())], update=True)<br>model_2.intersect_word2vec_format('pre-trained.txt', binary=False, lockf=1.0)<br>model_2.train(sentences, total_examples=total_examples, epochs=model_2.iter)
</code></pre>

                    <p style="border-top: 1px solid #dbdbdb; margin-top: 40px;"></p>
                    <div id="valine-thread"></div>
                    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
                    <script src='/js/Valine.min.js'></script>
                    <script>
                        new Valine({
                            el: '#valine-thread',
                            appId: 'DSTtKETb5UeyXIjoPTpRnC8Y-gzGzoHsz',
                            appKey: 'csHaHWqxD2Ujv84O7jaJWOSc',
                            verify: false,
                            avatar: 'robohash',
                            placeholder: '',
                            meta: ['nick', 'mail'],
                            requiredFields: ['nick'],
                            visitor: true,
                            lang: 'en'
                        })
                    </script>
                  
                    <footer>
                        <p style="padding: 5px 0 0 0; text-align: center; font-size: .9rem; border-top: 1px solid #dbdbdb;margin-top: 40px;">&#169; 2021 Jimmy Z. Hu<br>This website is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0.</a></p>
                    </footer>
                </div>
            </body>
        </html>
    